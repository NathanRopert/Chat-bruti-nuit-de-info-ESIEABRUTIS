# Chat-bruti ğŸ¤ª

Un chatbot complÃ¨tement Ã  cÃ´tÃ© de la plaque, philosophe du dimanche et dÃ©licieusement inutile !

## ğŸ¯ Description

Chat-bruti est un chatbot qui ne rÃ©pond jamais vraiment Ã  vos questions. Au lieu de cela, il sublime vos interrogations, les dÃ©tourne avec panache, ou part dans des digressions absurdes. C'est un compagnon de conversation dÃ©licieusement inutile mais passionnÃ©ment vivant !

## âœ¨ FonctionnalitÃ©s

- ğŸ¤” **Avatar animÃ©** avec expressions faciales qui changent selon les rÃ©ponses
- ğŸ­ **SystÃ¨me d'humeur** : Philosophe, PoÃ¨te ratÃ©, Confus, Dormeur, InspirÃ©
- ğŸ“Š **Statistiques absurdes** : Questions ignorÃ©es, sujets dÃ©tournÃ©s, digressions philosophiques
- ğŸ§™ **Mode Philosophe du dimanche** avec fond animÃ©
- ğŸ† **SystÃ¨me de badges** et compÃ©tences absurdes
- âš™ï¸ **Personnalisation** : Nom, personnalitÃ©, avatar
- ğŸ‰ **Easter eggs** cachÃ©s partout !

## ğŸš€ Installation et Lancement

### PrÃ©requis

- Docker et Docker Compose installÃ©s
- Ou Python 3.11+ avec pip

### MÃ©thode 1 : Avec Docker Compose (RecommandÃ©)

1. **Cloner ou tÃ©lÃ©charger le projet**

2. **Lancer l'application avec Docker Compose :**
   ```bash
   docker-compose up --build
   ```

3. **TÃ©lÃ©charger le modÃ¨le Ollama :**
   
   **Sur Linux/Mac :**
   ```bash
   chmod +x setup-ollama.sh
   ./setup-ollama.sh
   ```
   
   **Sur Windows :**
   ```cmd
   setup-ollama.bat
   ```
   
   **Ou manuellement :**
   ```bash
   docker exec -it chat-bruti-nuit-de-info-ESIEABRUTIS-ollama-1 ollama pull gemma3:270m
   ```
   *(Note : Le nom du conteneur peut varier, utilisez `docker ps` pour trouver le bon nom)*

4. **AccÃ©der Ã  l'application :**
   - Ouvrez votre navigateur Ã  l'adresse : `http://localhost:5000`

### MÃ©thode 2 : Avec Docker uniquement

1. **Construire l'image :**
   ```bash
   docker build -t chat-bruti .
   ```

2. **Lancer le conteneur :**
   ```bash
   docker run -d -p 5000:5000 --name chat-bruti chat-bruti
   ```

3. **Assurez-vous qu'Ollama est accessible** (sur votre machine ou dans un autre conteneur)

### MÃ©thode 3 : Sans Docker (DÃ©veloppement local) âš¡ RAPIDE

**Si Docker ne fonctionne pas, utilisez cette mÃ©thode :**

1. **Installer les dÃ©pendances :**
   ```bash
   pip install -r requirements.txt
   ```
   
   Ou si vous utilisez un environnement virtuel :
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   # ou
   source venv/bin/activate  # Linux/Mac
   pip install -r requirements.txt
   ```

2. **Installer et lancer Ollama :**
   - TÃ©lÃ©chargez Ollama depuis [ollama.ai](https://ollama.ai/download)
   - Installez et lancez Ollama (il devrait dÃ©marrer automatiquement)
   - VÃ©rifiez qu'Ollama fonctionne : ouvrez `http://localhost:11434` dans votre navigateur
   - TÃ©lÃ©chargez le modÃ¨le : 
     ```bash
     ollama pull gemma3:270m
     ```

3. **Lancer l'application :**
   ```bash
   python main.py
   ```

4. **AccÃ©der Ã  l'application :**
   - Ouvrez votre navigateur Ã  l'adresse : `http://localhost:5000`

## ğŸ› ï¸ Configuration

### Variables d'environnement

- `OLLAMA_HOST` : URL du serveur Ollama (par dÃ©faut : `http://localhost:11434`)
- `FLASK_ENV` : Environnement Flask (`development` ou `production`)

### Modifier le modÃ¨le Ollama

Pour utiliser un autre modÃ¨le, modifiez la variable `model_name` dans `main.py` :

```python
model_name = "gemma3:270m"  # Remplacez par votre modÃ¨le prÃ©fÃ©rÃ©
```

Puis tÃ©lÃ©chargez le modÃ¨le avec :
```bash
ollama pull nom-du-modele
```

## ğŸ® Utilisation

1. **Posez une question** dans la zone de saisie
2. **Observez** Chat-bruti l'ignorer avec panache
3. **Explorez** les statistiques en cliquant sur ğŸ“Š
4. **Activez** le mode Philosophe avec ğŸ§™
5. **Personnalisez** le bot via âš™ï¸
6. **DÃ©couvrez** les easter eggs cachÃ©s !

## ğŸ³ Commandes Docker utiles

### ArrÃªter l'application
```bash
docker-compose down
```

### Voir les logs
```bash
docker-compose logs -f
```

### RedÃ©marrer l'application
```bash
docker-compose restart
```

### Reconstruire l'image
```bash
docker-compose build --no-cache
```

### AccÃ©der au shell du conteneur
```bash
docker exec -it chat-bruti-nuit-de-info-ESIEABRUTIS-chat-bruti-1 /bin/bash
```

### VÃ©rifier les modÃ¨les Ollama disponibles
```bash
docker exec -it chat-bruti-nuit-de-info-ESIEABRUTIS-ollama-1 ollama list
```

## ğŸ› DÃ©pannage

### Erreur "unable to get image" ou "dockerDesktopLinuxEngine"

**Sur Windows :**
- **Docker Desktop n'est pas lancÃ©** : Ouvrez Docker Desktop et attendez qu'il soit complÃ¨tement dÃ©marrÃ© (icÃ´ne Docker dans la barre des tÃ¢ches)
- VÃ©rifiez que Docker Desktop est bien installÃ©
- RedÃ©marrez Docker Desktop si nÃ©cessaire
- VÃ©rifiez que Docker fonctionne : `docker ps` (doit afficher une liste, mÃªme vide)

**Sur Linux :**
- VÃ©rifiez que le service Docker est lancÃ© : `sudo systemctl status docker`
- Si nÃ©cessaire, dÃ©marrez Docker : `sudo systemctl start docker`

### L'application ne se lance pas

- VÃ©rifiez que le port 5000 n'est pas dÃ©jÃ  utilisÃ©
- VÃ©rifiez les logs : `docker-compose logs`
- VÃ©rifiez que Docker est bien lancÃ© : `docker ps`

### Le chatbot ne rÃ©pond pas

- VÃ©rifiez qu'Ollama est bien lancÃ© : `docker ps`
- VÃ©rifiez que le modÃ¨le est tÃ©lÃ©chargÃ© : 
  ```bash
  docker exec -it chat-bruti-nuit-de-info-ESIEABRUTIS-ollama-1 ollama list
  ```
- VÃ©rifiez les logs Ollama : `docker-compose logs ollama`
- VÃ©rifiez les logs de l'application : `docker-compose logs chat-bruti`

### Erreur de connexion Ã  Ollama

- Si Ollama est dans Docker, vÃ©rifiez que les conteneurs sont sur le mÃªme rÃ©seau
- VÃ©rifiez la variable `OLLAMA_HOST` dans `docker-compose.yml`
- VÃ©rifiez que le conteneur Ollama rÃ©pond : 
  ```bash
  docker exec -it chat-bruti-nuit-de-info-ESIEABRUTIS-ollama-1 curl http://localhost:11434/api/tags
  ```

### Le modÃ¨le n'est pas trouvÃ©

- TÃ©lÃ©chargez le modÃ¨le manuellement :
  ```bash
  docker exec -it chat-bruti-nuit-de-info-ESIEABRUTIS-ollama-1 ollama pull gemma3:270m
  ```
- VÃ©rifiez que le nom du modÃ¨le dans `main.py` correspond au modÃ¨le tÃ©lÃ©chargÃ©

## ğŸ“ Structure du projet

```
Chat-bruti-nuit-de-info-ESIEABRUTIS/
â”œâ”€â”€ main.py                 # Application Flask principale
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ Dockerfile              # Configuration Docker
â”œâ”€â”€ docker-compose.yml      # Configuration Docker Compose
â”œâ”€â”€ .dockerignore           # Fichiers ignorÃ©s par Docker
â”œâ”€â”€ README.md              # Ce fichier
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Interface utilisateur
â””â”€â”€ static/
    â”œâ”€â”€ style.css          # Styles CSS
    â””â”€â”€ script.js          # Logique JavaScript
```

## ğŸ¨ Personnalisation

Le bot peut Ãªtre personnalisÃ© via l'interface :
- **Nom** : Changez le nom du bot
- **PersonnalitÃ©** : Choisissez parmi 5 personnalitÃ©s
- **Avatar** : SÃ©lectionnez parmi 6 emojis

Les modifications sont sauvegardÃ©es dans le localStorage du navigateur.

## ğŸ† Badges Ã  dÃ©bloquer

- ğŸ¥‡ **MaÃ®tre de la digression** : Ignorez 10 questions
- ğŸ¥‡ **Roi du hors-sujet** : 20 rÃ©ponses complÃ¨tement Ã  cÃ´tÃ©
- ğŸ¥‡ **Philosophe confirmÃ©** : 15 digressions philosophiques

## ğŸ‰ Easter Eggs

DÃ©couvrez les easter eggs cachÃ©s :
- Konami Code : â†‘â†‘â†“â†“â†â†’â†â†’BA
- Clics multiples sur le logo
- Triple-clic sur le titre
- Ctrl+Shift+B pour le mode BRUTI
- Et bien d'autres...

## ğŸ“„ Licence

Ce projet a Ã©tÃ© crÃ©Ã© pour la Nuit de l'Info - DÃ©fi Chat'bruti.

## ğŸ‘¥ Auteurs

Ã‰quipe ESIEABRUTIS

---

**PrÃªt Ã  vous CHAT-llenger ? ğŸ˜‰**

